image:
  repository: ghcr.io/oremus-labs/triton-vllm
  tag: rocm7.1.0-vllm0.11.1
  pullPolicy: IfNotPresent

resources:
  limits:
    amd.com/gpu: 1
    cpu: "16"
    memory: "96Gi"
  requests:
    amd.com/gpu: 1
    cpu: "8"
    memory: "64Gi"

nodeSelector: {}
tolerations: []

modelRepo:
  hostPath: /mnt/ai-models
  mountPath: /models
  size: 2000Gi

service:
  type: ClusterIP
  httpPort: 8000
  grpcPort: 8001
  metricsPort: 8002

ingress:
  enabled: false
  className: traefik
  host: triton.oremuslabs.app
  path: /
  pathType: Prefix
  annotations: {}

env:
  TRITONSERVER_ARGS: >
    --model-repository=/models
    --model-control-mode=explicit
    --strict-model-config=false
    --http-port=8000
    --grpc-port=8001
    --metrics-port=8002

envFromSecrets: []
